{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79b6ff0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model= \"llama3.2:1b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42429c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='What is the capital of France?'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of France is Paris.', additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-09-05T13:28:56.001019Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1247882000, 'load_duration': 1107708625, 'prompt_eval_count': 32, 'prompt_eval_duration': 94756917, 'eval_count': 8, 'eval_duration': 44937958, 'model_name': 'llama3.2:1b'}, id='run--9f450be5-587f-49df-9eca-170bdea78e2c-0', usage_metadata={'input_tokens': 32, 'output_tokens': 8, 'total_tokens': 40})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template =PromptTemplate(\n",
    "    template = \"What is the capital of {country}?\",\n",
    "    input_variables = [\"country\"],\n",
    ")\n",
    "\n",
    "prompt = prompt_template.invoke({\"country\":\"France\"})\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "llm.invoke(prompt_template.invoke({\"country\":\"France\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9a35379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"The capital of South Korea is actually Pyongyang, which is also the capital of North Korea. However, I can tell you that Seoul is the de facto capital and the country's administrative center.\", additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-09-05T13:28:56.33396Z', 'done': True, 'done_reason': 'stop', 'total_duration': 322412292, 'load_duration': 51463125, 'prompt_eval_count': 74, 'prompt_eval_duration': 26448916, 'eval_count': 39, 'eval_duration': 243811375, 'model_name': 'llama3.2:1b'}, id='run--7f0ac23a-490a-4667-9b97-7e7e15ad85eb-0', usage_metadata={'input_tokens': 74, 'output_tokens': 39, 'total_tokens': 113})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "message_list=[\n",
    "    SystemMessage(content=\"You are a helpful assistant that can answer questions about the capital of countries.\"),\n",
    "    HumanMessage(content=\"What is the capital of South Korea?\"),\n",
    "    AIMessage(content=\"The capital of South Korea is Seoul.\"),\n",
    "    HumanMessage(content=\"What is the capital of South Korea?\")\n",
    "]\n",
    "llm.invoke(message_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "297f293c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a helpful assistant that can answer questions about the capital of countries.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the capital of France?', additional_kwargs={}, response_metadata={})]\n",
      "==================\n",
      "content='The capital of France is Paris.' additional_kwargs={} response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-09-05T13:32:20.829362Z', 'done': True, 'done_reason': 'stop', 'total_duration': 191419375, 'load_duration': 65361875, 'prompt_eval_count': 47, 'prompt_eval_duration': 80942958, 'eval_count': 8, 'eval_duration': 44596208, 'model_name': 'llama3.2:1b'} id='run--21aefe04-8ca8-4e72-9041-5dec88dacf66-0' usage_metadata={'input_tokens': 47, 'output_tokens': 8, 'total_tokens': 55}\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chat_prompt_template =ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that can answer questions about the capital of countries.\"\n",
    "    ),\n",
    "    (\n",
    "        \"human\",\n",
    "        \"What is the capital of {country}?\"\n",
    "    ),\n",
    "\n",
    "])\n",
    "\n",
    "chat_prompt = chat_prompt_template.invoke({\"country\":\"France\"})\n",
    "print(chat_prompt)\n",
    "print(\"==================\")\n",
    "ai_message = llm.invoke(chat_prompt_template.invoke({\"country\":\"France\"}))\n",
    "print(ai_message)\n",
    "print(\"==================\")\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "answer = output_parser.invoke(llm.invoke(prompt_template.invoke({\"country\":\"France\"})))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "702b5257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of France is Paris.', additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-09-05T13:32:20.829362Z', 'done': True, 'done_reason': 'stop', 'total_duration': 191419375, 'load_duration': 65361875, 'prompt_eval_count': 47, 'prompt_eval_duration': 80942958, 'eval_count': 8, 'eval_duration': 44596208, 'model_name': 'llama3.2:1b'}, id='run--21aefe04-8ca8-4e72-9041-5dec88dacf66-0', usage_metadata={'input_tokens': 47, 'output_tokens': 8, 'total_tokens': 55})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "640f5010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is Paris.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4a06073",
   "metadata": {},
   "outputs": [],
   "source": [
    "#아래보다 다음과 같은방식이 더 정석이다 / JsonOutputParser는 사용하지않는다\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class CountryDetail(BaseModel):\n",
    "    capital: str = Field(description=\"The capital of the country\")\n",
    "    population: int = Field(description=\"The population of the country\")\n",
    "    area: float = Field(description=\"The area of the country\")\n",
    "    currency: str = Field(description=\"The currency of the country\")\n",
    "    language: str = Field(description=\"The language of the country\")\n",
    "\n",
    "structured_llm = llm.with_structured_output(CountryDetail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0703e16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "country_detail_prompt=PromptTemplate(\n",
    "    template=\"\"\"Given following information about {country}:\n",
    "    What is the capital of {country}?\n",
    "    What is the population of {country}?\n",
    "    What is the area of {country}?\n",
    "    What is the currency of {country}?\n",
    "    What is the language of {country}?\n",
    "    What is the capital of {country}?\n",
    "    What is the population of {country}?\n",
    "\n",
    "    return it in JSON format and return the JSON dictionary only\n",
    "    \"\"\",\n",
    "    input_variables=[\"country\"]\n",
    ")\n",
    "\n",
    "# country_detail_prompt.invoke({\"country\":\"France\"})\n",
    "\n",
    "# output_parser = JsonOutputParser()\n",
    "json_ai_message = structured_llm.invoke(country_detail_prompt.invoke({\"country\":\"France\"}))\n",
    "# output_parser.invoke(json_ai_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1199015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountryDetail(capital='Paris', population=67, area=643.0, currency='Euro', language='French')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_ai_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4968b4db",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15d2e628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Paris'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_ai_message.capital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03aac8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_ai_message.population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d75dfb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'capital': 'Paris',\n",
       " 'population': 67,\n",
       " 'area': 643.0,\n",
       " 'currency': 'Euro',\n",
       " 'language': 'French'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_ai_message.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ed7f38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a helpful assistant that can answer questions about the capital of countries.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the capital of France?', additional_kwargs={}, response_metadata={})]\n",
      "==================\n",
      "content='The capital of France is Paris.' additional_kwargs={} response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-09-05T13:53:10.94183Z', 'done': True, 'done_reason': 'stop', 'total_duration': 711019292, 'load_duration': 571628708, 'prompt_eval_count': 47, 'prompt_eval_duration': 94087583, 'eval_count': 8, 'eval_duration': 44529958, 'model_name': 'llama3.2:1b'} id='run--41937fda-f5e6-4b8a-a80b-870d9e561a75-0' usage_metadata={'input_tokens': 47, 'output_tokens': 8, 'total_tokens': 55}\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chat_prompt_template =ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that can answer questions about the capital of countries.\"\n",
    "    ),\n",
    "    (\n",
    "        \"human\",\n",
    "        \"What is the capital of {country}?\"\n",
    "    ),\n",
    "\n",
    "])\n",
    "\n",
    "chat_prompt = chat_prompt_template.invoke({\"country\":\"France\"})\n",
    "print(chat_prompt)\n",
    "print(\"==================\")\n",
    "ai_message = llm.invoke(chat_prompt_template.invoke({\"country\":\"France\"}))\n",
    "print(ai_message)\n",
    "print(\"==================\")\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "answer = output_parser.invoke(llm.invoke(prompt_template.invoke({\"country\":\"France\"})))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b277ebf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e70659",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
